{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cfek8QsFM5yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiMWCM16DCBq"
      },
      "outputs": [],
      "source": [
        "#Importing neccessary libraries for data manipuation and data visualization\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the dimensions of all the images to 64*64\n",
        "img_width = 64\n",
        "img_height = 64\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/TrainingSet/Old_DataSet _PP/Old_Classification/Train'\n",
        "validation_data_dir = '/content/drive/MyDrive/TrainingSet/Old_DataSet _PP/Old_Classification/Validation'\n",
        "\n",
        "train_samples = 30\n",
        "validation_samples = 15\n",
        "epochs = 100\n",
        "batch_size = 4          # Model generation in each epoch in batch size of 4 \n",
        "\n",
        "# Checking for TensorFlow\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "3AMdTvO2M2On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conv2D : Two dimenstional convulational model.\n",
        "# 32 : Input for next layer\n",
        "# (3,3) convulonational windows size\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # Output convert into one dimension layer and will go to Dense layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "Bzs_34MlM2s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=keras.optimizers.Adam(lr=.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aTHjIqzRM2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "metadata": {
        "id": "TPhPy-8KM2x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "TknIkU4GM20T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "#normal + cancer in train"
      ],
      "metadata": {
        "id": "nDld_-04M23B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)"
      ],
      "metadata": {
        "id": "Xaa5miI1NLlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(train_generator)"
      ],
      "metadata": {
        "id": "_21UdGOsNLns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "\n",
        "def imshow(image_RGB):\n",
        "  io.imshow(image_RGB)\n",
        "  io.show()"
      ],
      "metadata": {
        "id": "hpeavI4RNLrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "image_batch,label_batch = train_generator.next()\n",
        "\n",
        "print(len(image_batch))\n",
        "for i in range(0,len(image_batch)):\n",
        "    image = image_batch[i]\n",
        "    print(label_batch[i])\n",
        "    imshow(image)"
      ],
      "metadata": {
        "id": "FOkkDRAJNLt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "id": "9BAMUse-NLw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit_generator(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=train_samples // batch_size,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=validation_samples // batch_size)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_samples)"
      ],
      "metadata": {
        "id": "ANuo3pU9NL0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "val_acc=val_acc[28]\n",
        "\n",
        "t=max(train_acc)*100\n",
        "v=val_acc*100\n",
        "print(\"Training Accuracy: %.1f\"%t)\n",
        "print(\"Validation Accuracy: %.1f\"%v)"
      ],
      "metadata": {
        "id": "WePwpYTADGEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "REqktbgeNYBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_dir_path='/content/drive/MyDrive/TrainingSet/Old_DataSet _PP/Old_Classification/Test/'\n",
        "onlyfiles = [f for f in listdir(predict_dir_path) if isfile(join(predict_dir_path, f))]\n",
        "print(onlyfiles)"
      ],
      "metadata": {
        "id": "BAtPelaUNYEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting images\n",
        "from keras.preprocessing import image\n",
        "cancer_counter = 0 \n",
        "normal_counter  = 0\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(predict_dir_path+file, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size=10)\n",
        "    classes = classes[0][0]\n",
        "    \n",
        "    if classes == 0:\n",
        "        print(file + \": \" + 'cancer')\n",
        "        cancer_counter += 1\n",
        "    else:\n",
        "        print(file + \": \" + 'normal')\n",
        "        normal_counter += 1\n",
        "print(\"Total Cancer :\",cancer_counter)\n",
        "print(\"Total Normal :\",normal_counter)"
      ],
      "metadata": {
        "id": "cc5CFkScNYGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "OdX1iAcvNdXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/TrainingSet/Old_DataSet _PP/Old_Classification/Test/14.jpg'\n",
        "img = image.load_img(path , target_size =(64,64))\n",
        "x = image.img_to_array(img)\n",
        "plt.imshow(x/255.)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images , batch_size = 2)\n",
        "#print(classes)\n",
        "if classes[0] <0.5 :\n",
        "  print(\"Cancerous Tumor\")\n",
        "else:\n",
        "  print(\"Benign Tumor\")"
      ],
      "metadata": {
        "id": "Ral5qeuyNdaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/TrainingSet/Old_DataSet _PP/Old_Classification/Test/n23.jpg'\n",
        "img = image.load_img(path , target_size =(64,64))\n",
        "x = image.img_to_array(img)\n",
        "plt.imshow(x/255.)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images , batch_size = 2)\n",
        "#print(classes)\n",
        "if classes[0] <0.5 :\n",
        "  print(\"Cancerous Tumor\")\n",
        "else:\n",
        "  print(\"Benign Tumor\")"
      ],
      "metadata": {
        "id": "bIQ0m0T4NhIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = model.predict(validation_generator,verbose=1)\n"
      ],
      "metadata": {
        "id": "PgXvcJ-cNhKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr , tpr , _ = roc_curve(validation_generator.classes , preds)\n",
        "roc_auc = auc (fpr , tpr)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z82e28xjNhNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color = 'darkorange', lw=lw,\n",
        "         label = 'ROC curve (area = %0.f)' % roc_auc)\n",
        "plt.plot([0 , 1], [0 , 1], color = 'navy',lw=lw, linestyle = '--')\n",
        "plt.xlim([0.0 , 1.0])\n",
        "plt.ylim([0.0 , 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Reciever Operating Characteristics')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Q5klRh2Nmpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = model.predict_generator(generator=validation_generator)\n",
        "\n",
        "y_true = validation_generator.classes\n",
        "# print(y_true)\n",
        "\n",
        "y_pred=prob>0.5\n",
        "# print(y_pred)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "mat = confusion_matrix(y_true , y_pred)\n",
        "#print(mat)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true , y_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(cm , annot=True , ax=ax)"
      ],
      "metadata": {
        "id": "fPABRSOLNmsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cm[1, 1]\n",
        "TN = cm[0, 0]\n",
        "FP = cm[0, 1]\n",
        "FN = cm[1, 0]"
      ],
      "metadata": {
        "id": "bCDc_L7jNmu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sensitivity or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "TPR_f = TPR*100\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "TNR_f = TNR*100\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "PPV_f = PPV*100\n",
        "# Overall accuracy for each class\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "ACC_f = ACC*100\n",
        "#Recall\n",
        "recall = (TP/(TP+FN))\n",
        "recall_f = recall*100\n",
        "#F1 Score\n",
        "F1 = (2*((PPV*recall)/(PPV+recall)))\n",
        "F1_f = F1*100\n",
        "\n",
        "\n",
        "print(\"False Positive                                  : \",FP)\n",
        "print(\"False Neagtive                                  : \",FN)\n",
        "print(\"True Positive                                   : \",TP)\n",
        "print(\"True Negative                                   : \",TN)\n",
        "print(\"True Positive Rate (Sensitivity)                : %.2f \"%TPR_f)\n",
        "print(\"True Negative Rate (Specificity)                : %.2f \"%TNR_f)\n",
        "print(\"Precision                                       : %.2f \"%PPV_f)\n",
        "print(\"Accuracy for each class                         : %.2f \"%ACC_f)\n",
        "print(\"Recall                                          : %.2f \"%recall_f)\n",
        "print(\"F1 Score                                        : %.2f \"%F1_f) "
      ],
      "metadata": {
        "id": "z_1cSrLoNmxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}